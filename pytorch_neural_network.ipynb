{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2HwZCAHucUAa5q80vfJlq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KavyaPremaseelan/Neural-Network/blob/main/pytorch_neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KhVqQ1bcm9J7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,),(0.3081))])"
      ],
      "metadata": {
        "id": "TYMOxDPInARr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset=datasets.MNIST('data',train=True,download=True,transform=transform)"
      ],
      "metadata": {
        "id": "IxIZwe0Vq1fP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e1b6f5b-fb8f-481d-cc99-5e864cdd6ea4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 91698451.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 114603305.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 28140490.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 23724195.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=64,shuffle=True)"
      ],
      "metadata": {
        "id": "nq_OtUywql2S"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Neural(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Neural, self).__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)  # Adding a hidden layer with 64 neurons\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))  # Applying activation to the hidden layer\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "net = Neural()\n"
      ],
      "metadata": {
        "id": "flkz1p6xrKPS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer=optim.SGD(net.parameters(),lr=0.01,momentum=0.5)"
      ],
      "metadata": {
        "id": "XfEcuqBy1Sjx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs=10\n",
        "for epoch in range(num_epochs):\n",
        "  for batch_idx,(data,target) in enumerate (train_loader):\n",
        "    optimizer.zero_grad()\n",
        "    output=net(data)\n",
        "    loss =criterion(output,target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if batch_idx % 100==0:\n",
        "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "\n",
        "test_dataset=datasets.MNIST('data',train=False,download=True,transform=transform)\n",
        "test_loader=torch.utils.data.DataLoader(test_dataset,batch_size=1000,shuffle=True)\n",
        "correct=0\n",
        "total=0\n",
        "with torch.no_grad():\n",
        "  output=net(data)\n",
        "  _,predicted=torch.max(output.data,1)\n",
        "  total+=target.size(0)\n",
        "  correct+=(predicted==target).sum().item()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyUGf-Eo2kqf",
        "outputId": "d27af8e5-88b3-4e24-8fde-f7033bebf754"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.306441\n",
            "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 1.210301\n",
            "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.582963\n",
            "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 0.431529\n",
            "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.274221\n",
            "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.223834\n",
            "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.267334\n",
            "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.682857\n",
            "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.409863\n",
            "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.321569\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.337818\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.152175\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.247087\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.448805\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.210920\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.338293\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.189758\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.180202\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.119425\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.192734\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.243112\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.227490\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.126687\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.170639\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.295926\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.130556\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.116505\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.059771\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.162241\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.099289\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.149391\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.117311\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.143247\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.119405\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.294638\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.208519\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.120265\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.090816\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.134353\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.113001\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.040444\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.115965\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.118514\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.203395\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.084639\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.148895\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.124060\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.095352\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.148598\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.161966\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.071748\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.064676\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.072773\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.052540\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.094996\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.208814\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.088781\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.090087\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.069011\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.119057\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.026758\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.074313\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.082494\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.058672\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.094489\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.253790\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.060435\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.075150\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.041477\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.054674\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.132820\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.040026\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.090051\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.034270\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.053669\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.100413\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.016237\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.012337\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.093154\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.077884\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.012053\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.080824\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.096071\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.027598\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.072570\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.181744\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.057495\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.084316\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.058625\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.061343\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.013478\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.096078\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.066541\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.076974\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.047069\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.153569\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.058578\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.042613\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.083108\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.055284\n",
            "Accuracy of the network on the 10000 test images: 100 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## neural network after adding hidden layer"
      ],
      "metadata": {
        "id": "x2MBJ2xR5v_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define the neural network with one hidden layer\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 128)  # Input layer to hidden layer\n",
        "        self.relu = nn.ReLU()  # Activation function\n",
        "        self.fc2 = nn.Linear(128, 10)  # Hidden layer to output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)  # Flatten the input\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model, loss function, and optimizer\n",
        "net = SimpleNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "# Assuming you have the training loop as you provided in the original code\n",
        "\n",
        "# Backward propagation within the training loop\n",
        "for epoch in range(num_epochs):\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        output = net(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "# Testing loop (as corrected previously)\n",
        "test_dataset = datasets.MNIST('data', train=False, download=True, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1000, shuffle=True)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "        output = net(data)\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        total += target.size(0)\n",
        "        correct += (predicted == target).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GPhAg5L4_dU",
        "outputId": "7ace4133-3f85-40bd-f0f5-b9ce5460c43d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.330929\n",
            "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 0.583830\n",
            "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.435860\n",
            "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 0.239165\n",
            "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.279667\n",
            "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.411103\n",
            "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.327023\n",
            "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.325842\n",
            "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.199743\n",
            "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.347740\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.274206\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.167399\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.263631\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.228424\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.300857\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.162950\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.300122\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.194484\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.313671\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.227622\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.267287\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.159632\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.189373\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.202680\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.146987\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.244976\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.353816\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.357776\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.130201\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.113847\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.217269\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.095769\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.108999\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.156363\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.085418\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.171305\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.036111\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.180493\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.094793\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.085552\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.267672\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.095782\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.124034\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.112900\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.250524\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.119497\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.096390\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.247493\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.198439\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.134158\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.199453\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.163226\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.154737\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.065349\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.032473\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.129817\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.092882\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.067827\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.185970\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.122909\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.136960\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.052824\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.064514\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.064247\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.110547\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.104739\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.034912\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.242198\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.061122\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.138113\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.055710\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.061148\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.120615\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.080106\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.034829\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.097500\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.101857\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.071407\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.093922\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.157435\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.109493\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.188396\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.093540\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.069996\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.132160\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.065241\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.045541\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.067036\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.085117\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.058380\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.051338\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.025560\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.062182\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.086672\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.202117\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.059157\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.076758\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.129478\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.072140\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.033268\n",
            "Accuracy of the network on the 10000 test images: 97 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## other dataset(Fashion-MNIST)"
      ],
      "metadata": {
        "id": "0I8icTb2A6SC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define the neural network with one hidden layer\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 128)  # Input layer to hidden layer\n",
        "        self.relu = nn.ReLU()  # Activation function\n",
        "        self.fc2 = nn.Linear(128, 10)  # Hidden layer to output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)  # Flatten the input\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model, loss function, and optimizer\n",
        "net = SimpleNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "# Assuming you have the training loop as you provided in the original code\n",
        "\n",
        "# Backward propagation within the training loop\n",
        "for epoch in range(num_epochs):\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        output = net(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "# Testing loop (as corrected previously)\n",
        "test_dataset = datasets.FashionMNIST('data', train=False, download=True, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1000, shuffle=True)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "        output = net(data)\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        total += target.size(0)\n",
        "        correct += (predicted == target).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceQpIItcAnlX",
        "outputId": "4de45c8f-7f11-4245-f51e-ce1498f51e2d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.274026\n",
            "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 0.710608\n",
            "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.496667\n",
            "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 0.391644\n",
            "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.265582\n",
            "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.395036\n",
            "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.320538\n",
            "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.428797\n",
            "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.247475\n",
            "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.205275\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.218119\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.237038\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.428557\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.303196\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.350555\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.082498\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.238912\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.215370\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.263397\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.124983\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.232642\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.127312\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.325297\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.140865\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.346027\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.207300\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.237015\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.209821\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.302670\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.433755\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.132521\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.255709\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.192531\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.085473\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.108521\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.103978\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.095183\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.148141\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.088092\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.155651\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.157915\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.252063\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.299053\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.103044\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.074107\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.156270\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.083847\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.052543\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.221556\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.080212\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.290417\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.070360\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.165083\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.177531\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.120480\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.157614\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.120671\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.177327\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.190107\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.068904\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.115880\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.082207\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.115964\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.061755\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.126748\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.238038\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.112936\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.173734\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.075270\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.084548\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.154742\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.205666\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.029195\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.061316\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.089106\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.045716\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.084836\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.062922\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.049178\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.125452\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.057356\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.053589\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.096964\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.033982\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.054088\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.139733\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.210668\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.053806\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.120150\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.094343\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.115460\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.036772\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.022897\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.118099\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.082793\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.076820\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.030577\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.108929\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.208823\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.132180\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:01<00:00, 15634351.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 264981.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 4952172.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 29178752.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Accuracy of the network on the 10000 test images: 6 %\n"
          ]
        }
      ]
    }
  ]
}